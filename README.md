# Parallels_HW
В данном репозитории будут представлены лабораторные работы по курсу Параллельное программирование, ММФ, НГУ

# OpenMP_SLAU
Решение СЛАУ с плотной матрицей итерационным методом Гаусса.

    Для верификации метода генерировалась матрица, решение которой известно - на диагонали значения n + 1, где n - размер матрицы, 
остальные значения - единицы. Вектор решений для такой матрицы полностью заполнен единицами.

Расчет был проведен на ПК Apple MacBook Air 2022 
Процессор M2 - 4 производительных ядер и 4 энергоэффективных (гибридная архитектура), 1 поток на ядро.

Результаты (время, ускорение, эффективность) - https://docs.google.com/spreadsheets/d/1W31IW7T3Pzd-LqoeukDTXBTbZXZnTd2NoBF0d5Day3s/edit?gid=0#gid=0.

Итоги: 
- видно, что на наименьшем размере вектора наименьшая эффективность (слабое ускорение), что связано с расходами на "общение" параллельных процессов.
- На гибридном процессоре с 4 производительными и 4 энергоэффективными ядрами использование всех 8 потоков замедляет вычисления из-за дисбаланса нагрузки, поскольку быстрые ядра вынуждены ждать медленные, тогда как 4 потока на производительных ядрах работают оптимально.


# MPI_SLAU
Также как и для OpenMP_SLAU, было проведено решение СЛАУ итерационным методом Гаусса. 

Для честного сравнения методов пралась та же самая матрица, что и в случае OpenMP

ПК - Apple MacBook Air 2022, Процессор M2 - 4 производительных ядер и 4 эффективных, 1 поток на ядро.

Результаты (время, ускорение, эффективность) - https://docs.google.com/spreadsheets/d/1W31IW7T3Pzd-LqoeukDTXBTbZXZnTd2NoBF0d5Day3s/edit?gid=1808621195#gid=1808621195

Итоги: так же, как и в случае openMP наблюдается рост эффективности при росте размера исходных матриц - уменьшается доля времени на накладные расходы

# CUDA_SLAU
Аналогичное решение СЛАУ с написанием кода на CUDA для вычисления на gpu. 

Вычисление проводилось на кластере ИТ СО РАН "Каскад" на видеокарте NVIDIA A100.

Результаты - (время, ускорение, эффективность)

Итоги: 

# MATRIX_MULTIPLICATION
В рамках данного задания проводилось вычисление произведения матриц в MPI на 2D решетке (https://ssd.sscc.ru/sites/default/files/content/attach/343/parallel_lab3_2020.pdf)

Расчет был проведен на ПК Apple MacBook Air 2022 
Процессор M2 - 4 производительных ядер и 4 энергоэффективных (гибридная архитектура), 1 поток на ядро.

Чтобы не сталкиваться с дисбалансом нагрузки, вычисления проводились на 1, 2 и 4 производительных ядрах

Результаты (время, ускорение, эффективность) - https://docs.google.com/spreadsheets/d/1W31IW7T3Pzd-LqoeukDTXBTbZXZnTd2NoBF0d5Day3s/edit?gid=148107311#gid=148107311

Итоги: - виден заметный прирост эффективности параллельных расчетов, в сравнении с итерационным решением СЛАУ, что можно объяснить тем, что вычисления перемножений блоков матриц не зависят от таких параметров обусловленность матрицы, эффективность итерационного метода и тд, а лишь от размеров матриц и доступных вычислительных ресурсов, что обеспечивает идеальную масштабируемость и почти линейный рост производительности с увеличением числа потоков для больших матриц